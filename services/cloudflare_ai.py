"""
Cloudflare Workers AI Integration –¥–ª—è NutriBuddy
===============================================

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:
‚Ä¢ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –µ–¥—ã (UForm-Gen2) ‚Äî –º–∞—Å—Å–∏–≤ –±–∞–π—Ç–æ–≤, –Ω–µ base64!
‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ (Whisper) ‚Äî multipart/form-data
‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ—Ü–µ–ø—Ç–æ–≤ (Llama 3) ‚Äî messages API
‚Ä¢ –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ (TinyLlama) ‚Äî –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –∑–∞–¥–∞—á

–í–∞–∂–Ω–æ: Vision-–º–æ–¥–µ–ª–∏ Cloudflare —Ç—Ä–µ–±—É—é—Ç image –∫–∞–∫ array of integers (0-255),
–∞ –ù–ï –∫–∞–∫ base64-—Å—Ç—Ä–æ–∫—É. –≠—Ç–æ –∫–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ –æ—Ç –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –¥—Ä—É–≥–∏—Ö API.

–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è:
‚Ä¢ https://developers.cloudflare.com/workers-ai/models/
‚Ä¢ https://developers.cloudflare.com/workers-ai/configuration/open-ai-compatibility/
"""

import aiohttp
import os
import logging
from typing import Optional, Dict, List, Union
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# =============================================================================
# üîê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# =============================================================================

CLOUDFLARE_ACCOUNT_ID = os.getenv("CLOUDFLARE_ACCOUNT_ID")
CLOUDFLARE_API_TOKEN = os.getenv("CLOUDFLARE_API_TOKEN")

if not CLOUDFLARE_ACCOUNT_ID or not CLOUDFLARE_API_TOKEN:
    logger.warning("‚ö†Ô∏è Cloudflare credentials not set ‚Äî AI functions will fail")

BASE_URL = f"https://api.cloudflare.com/client/v4/accounts/{CLOUDFLARE_ACCOUNT_ID}/ai/run/"

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
MODELS = {
    # Vision (–∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
    "uform_gen2": "@cf/unum/uform-gen2-qwen-500m",
    "llava": "@cf/llava-hf/llava-1.5-7b-hf",
    
    # Audio (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏)
    "whisper": "@openai/whisper",
    
    # Text generation (–≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞)
    "llama3": "@cf/meta/llama-3-8b-instruct",
    "llama3_1": "@cf/meta/llama-3.1-8b-instruct",
    "mistral": "@cf/mistral/mistral-7b-instruct-v0.1",
    
    # Fast text (–±—ã—Å—Ç—Ä—ã–µ –∑–∞–¥–∞—á–∏)
    "tinyllama": "@cf/tinyllama/tinyllama-1.1b-chat-v1.0",
}

# –¢–∞–π–º–∞—É—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (—Å–µ–∫—É–Ω–¥—ã)
DEFAULT_TIMEOUTS = {
    "vision": 30,
    "audio": 60,
    "text": 45,
}


# =============================================================================
# üîß –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =============================================================================

def _bytes_to_array(image_bytes: bytes) -> List[int]:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç bytes –≤ —Å–ø–∏—Å–æ–∫ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª 0-255 –¥–ª—è Cloudflare AI.
    
    Cloudflare Vision API —Ç—Ä–µ–±—É–µ—Ç image –∫–∞–∫ –º–∞—Å—Å–∏–≤ –±–∞–π—Ç–æ–≤, –∞ –Ω–µ base64!
    
    Args:
        image_bytes: –°—ã—Ä—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        
    Returns:
        List[int]: –°–ø–∏—Å–æ–∫ —Ü–µ–ª—ã—Ö —á–∏—Å–µ–ª 0-255
    """
    return list(image_bytes)


def _validate_credentials() -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ª–∏ —É—á—ë—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ Cloudflare"""
    if not CLOUDFLARE_ACCOUNT_ID or not CLOUDFLARE_API_TOKEN:
        logger.error("‚ùå Cloudflare credentials not configured")
        return False
    return True


async def _make_request(
    endpoint: str,
    payload: Dict,
    timeout: int = 30,
    use_form: bool = False
) -> Optional[Dict]:
    """
    –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è HTTP-–∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Cloudflare AI API.
    
    Args:
        endpoint: URL —ç–Ω–¥–ø–æ–∏–Ω—Ç–∞ (–ø–æ–ª–Ω—ã–π –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π)
        payload: –î–∞–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å–∞
        timeout: –¢–∞–π–º–∞—É—Ç –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        use_form: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å multipart/form-data (–¥–ª—è –∞—É–¥–∏–æ)
        
    Returns:
        Dict: –û—Ç–≤–µ—Ç API –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not _validate_credentials():
        return None
    
    url = endpoint if endpoint.startswith("http") else f"{BASE_URL}{endpoint}"
    headers = {"Authorization": f"Bearer {CLOUDFLARE_API_TOKEN}"}
    
    async with aiohttp.ClientSession() as session:
        try:
            if use_form:
                # –î–ª—è Whisper: multipart/form-data
                from aiohttp import FormData
                data = FormData()
                for key, value in payload.items():
                    data.add_field(key, value)
                
                async with session.post(
                    url,
                    headers=headers,
                    data=data,
                    timeout=aiohttp.ClientTimeout(total=timeout)
                ) as resp:
                    return await _process_response(resp)
            else:
                # –î–ª—è JSON-–∑–∞–ø—Ä–æ—Å–æ–≤ (vision, text)
                headers["Content-Type"] = "application/json"
                
                async with session.post(
                    url,
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=timeout)
                ) as resp:
                    return await _process_response(resp)
                    
        except aiohttp.ClientConnectionError as e:
            logger.error(f"üåê Connection error: {e}")
            return None
        except aiohttp.ClientTimeout as e:
            logger.error(f"‚è±Ô∏è Request timeout: {e}")
            return None
        except Exception as e:
            logger.exception(f"üí• Unexpected error in _make_request: {e}")
            return None


async def _process_response(resp: aiohttp.ClientResponse) -> Optional[Dict]:
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Cloudflare API.
    
    Args:
        resp: –û–±—ä–µ–∫—Ç –æ—Ç–≤–µ—Ç–∞ aiohttp
        
    Returns:
        Dict: –†–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON –∏–ª–∏ None
    """
    try:
        if resp.status == 200:
            return await resp.json()
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –ø–æ –∫–æ–¥–∞–º —Å—Ç–∞—Ç—É—Å–∞
        error_text = await resp.text()
        
        if resp.status == 401:
            logger.error("üîê Authentication failed ‚Äî check API token")
        elif resp.status == 403:
            logger.error("üö´ Access denied ‚Äî check account ID and model permissions")
        elif resp.status == 400:
            logger.error(f"‚ùå Bad request: {error_text[:200]}")
        elif resp.status == 429:
            logger.error("‚è±Ô∏è Rate limit exceeded ‚Äî try again later")
        elif resp.status >= 500:
            logger.error(f"üîß Server error {resp.status}: {error_text[:200]}")
        else:
            logger.error(f"‚ùå API error {resp.status}: {error_text[:200]}")
        
        return None
        
    except Exception as e:
        logger.error(f"üí• Error processing response: {e}")
        return None


# =============================================================================
# üîç –ê–ù–ê–õ–ò–ó –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô (Vision AI)
# =============================================================================

async def analyze_food_image(
    image_bytes: bytes,
    prompt: str = "–û–ø–∏—à–∏ –µ–¥—É –Ω–∞ —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. –£–∫–∞–∂–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –±–ª—é–¥–∞ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, 2-3 —Å–ª–æ–≤–∞.",
    max_tokens: int = 150,
    model: str = "uform_gen2"
) -> Optional[str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ–¥—ã —á–µ—Ä–µ–∑ Cloudflare Vision AI.
    
    üîë –ö–õ–Æ–ß–ï–í–û–ï: image –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∫–∞–∫ array of bytes (List[int]), –ù–ï base64!
    
    Args:
        image_bytes: –°—ã—Ä—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (JPEG/PNG)
        prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ç—Ä–µ–±—É–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ MODELS (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "uform_gen2")
        
    Returns:
        str: –û–ø–∏—Å–∞–Ω–∏–µ –µ–¥—ã –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
    Example:
        >>> with open("food.jpg", "rb") as f:
        ...     result = await analyze_food_image(f.read())
        >>> print(result)  # "–∂–∞—Ä–µ–Ω–∞—è –∫—É—Ä–∏—Ü–∞ —Å –æ–≤–æ—â–∞–º–∏"
    """
    try:
        if not _validate_credentials():
            return None
        
        # üî• –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º bytes ‚Üí array of integers 0-255
        image_array = _bytes_to_array(image_bytes)
        logger.info(f"üìä Image converted: {len(image_array)} bytes ‚Üí array")
        
        # –§–æ—Ä–º–∞—Ç payload –¥–ª—è UForm-Gen2 –∏ –ø–æ–¥–æ–±–Ω—ã—Ö vision-–º–æ–¥–µ–ª–µ–π
        payload = {
            "image": image_array,  # ‚Üê –ú–ê–°–°–ò–í, –Ω–µ base64!
            "prompt": prompt,
            "max_tokens": max_tokens
        }
        
        model_endpoint = MODELS.get(model, MODELS["uform_gen2"])
        logger.info(f"üì§ Sending to {model_endpoint}")
        
        result = await _make_request(
            model_endpoint,
            payload,
            timeout=DEFAULT_TIMEOUTS["vision"]
        )
        
        if result:
            # –†–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            if "result" in result:
                description = result["result"].get("description", "")
            elif "choices" in result:
                # OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π —Ñ–æ—Ä–º–∞—Ç
                description = result["choices"][0].get("message", {}).get("content", "")
            else:
                description = str(result)
            
            if description and len(description.strip()) > 5:
                logger.info(f"‚úÖ Vision success: {description[:100]}...")
                return description.strip()
            
            logger.warning("‚ö†Ô∏è Empty description in response")
            return None
        
        logger.warning("‚ö†Ô∏è No result from Vision API")
        return None
        
    except Exception as e:
        logger.exception(f"üí• analyze_food_image error: {e}")
        return None


async def analyze_image_with_llava(
    image_bytes: bytes,
    prompt: str = "What is in this image?",
    max_tokens: int = 200
) -> Optional[str]:
    """
    –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLaVA-1.5 –º–æ–¥–µ–ª—å.
    –ú–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Ç–∏–ø–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
    
    Args:
        image_bytes: –°—ã—Ä—ã–µ –±–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        
    Returns:
        str: –û–ø–∏—Å–∞–Ω–∏–µ –∏–ª–∏ None
    """
    return await analyze_food_image(
        image_bytes,
        prompt=prompt,
        max_tokens=max_tokens,
        model="llava"
    )


# =============================================================================
# üé§ –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –ì–û–õ–û–°–ê (Whisper)
# =============================================================================

async def transcribe_audio(
    audio_bytes: bytes,
    language: str = "ru",
    temperature: float = 0.0,
    model: str = "whisper"
) -> Optional[str]:
    """
    –†–∞—Å–ø–æ–∑–Ω–∞—ë—Ç —Ä–µ—á—å –≤ –∞—É–¥–∏–æ—Ñ–∞–π–ª–µ —á–µ—Ä–µ–∑ Cloudflare Whisper.
    
    –ê—É–¥–∏–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ .ogg (–∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç Telegram Voice).
    
    Args:
        audio_bytes: –°—ã—Ä—ã–µ –±–∞–π—Ç—ã –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        language: –ö–æ–¥ —è–∑—ã–∫–∞ ('ru', 'en', 'de', etc.)
        temperature: –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (0.0 = —Ç–æ—á–Ω–æ, 1.0 = –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ)
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "whisper")
        
    Returns:
        str: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
    Example:
        >>> with open("voice.ogg", "rb") as f:
        ...     text = await transcribe_audio(f.read(), language="ru")
        >>> print(text)  # "–∑–∞–ø–∏—à–∏ –≥—Ä–µ—á–∫—É —Å –∫—É—Ä–∏—Ü–µ–π –Ω–∞ –æ–±–µ–¥"
    """
    try:
        if not _validate_credentials():
            return None
        
        from aiohttp import FormData
        
        # Whisper API –ø—Ä–∏–Ω–∏–º–∞–µ—Ç multipart/form-data
        data = FormData()
        data.add_field('file', audio_bytes, filename='voice.ogg', content_type='audio/ogg')
        data.add_field('model', MODELS.get(model, MODELS["whisper"]))
        data.add_field('language', language)
        data.add_field('temperature', str(temperature))
        
        logger.info(f"üé§ Sending audio to Whisper ({len(audio_bytes)} bytes, lang={language})")
        
        # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å, —Ç.–∫. FormData –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å _make_request
        url = f"{BASE_URL}{MODELS.get(model, MODELS['whisper'])}"
        headers = {"Authorization": f"Bearer {CLOUDFLARE_API_TOKEN}"}
        
        async with aiohttp.ClientSession() as session:
            async with session.post(
                url,
                headers=headers,
                data=data,
                timeout=aiohttp.ClientTimeout(total=DEFAULT_TIMEOUTS["audio"])
            ) as resp:
                
                if resp.status == 200:
                    result = await resp.json()
                    text = result.get("result", {}).get("text", "")
                    if text:
                        logger.info(f"‚úÖ Whisper success: {text[:100]}...")
                        return text.strip()
                    logger.warning("‚ö†Ô∏è Empty text from Whisper")
                    return None
                else:
                    error_text = await resp.text()
                    logger.error(f"‚ùå Whisper error {resp.status}: {error_text[:200]}")
                    return None
                    
    except Exception as e:
        logger.exception(f"üí• transcribe_audio error: {e}")
        return None


# =============================================================================
# üß† –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê (LLM)
# =============================================================================

async def generate_recipe(
    ingredients: str,
    diet_type: str = "–æ–±—ã—á–Ω–æ–µ",
    difficulty: str = "—Å—Ä–µ–¥–Ω—è—è",
    max_tokens: int = 800,
    model: str = "llama3"
) -> Optional[str]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ Llama 3.
    
    Args:
        ingredients: –°–ø–∏—Å–æ–∫ –∏–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∫—É—Ä–∏—Ü–∞, —Ä–∏—Å, –±—Ä–æ–∫–∫–æ–ª–∏")
        diet_type: –¢–∏–ø –ø–∏—Ç–∞–Ω–∏—è (–æ–±—ã—á–Ω–æ–µ/–≤–µ–≥–µ—Ç–∞—Ä–∏–∞–Ω—Å–∫–æ–µ/–≤–µ–≥–∞–Ω—Å–∫–æ–µ/–∫–µ—Ç–æ/–ø–∞–ª–µ–æ)
        difficulty: –°–ª–æ–∂–Ω–æ—Å—Ç—å (–ª—ë–≥–∫–∞—è/—Å—Ä–µ–¥–Ω—è—è/—Å–ª–æ–∂–Ω–∞—è)
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "llama3")
        
    Returns:
        str: –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        
    Example:
        >>> recipe = await generate_recipe("–∫—É—Ä–∏—Ü–∞, —Ä–∏—Å, –æ–≤–æ—â–∏", diet_type="–∫–µ—Ç–æ")
        >>> print(recipe)  # –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç —Å –ö–ë–ñ–£
    """
    prompt = f"""–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —à–µ—Ñ-–ø–æ–≤–∞—Ä –∏ –Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥.
–°–æ—Å—Ç–∞–≤—å –ø–æ–¥—Ä–æ–±–Ω—ã–π —Ä–µ—Ü–µ–ø—Ç –±–ª—é–¥–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

ü•ò –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã: {ingredients}
ü•ó –¢–∏–ø –ø–∏—Ç–∞–Ω–∏—è: {diet_type}
üë®‚Äçüç≥ –°–ª–æ–∂–Ω–æ—Å—Ç—å: {difficulty}

üìã –§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏):
1. üçΩÔ∏è –ù–∞–∑–≤–∞–Ω–∏–µ –±–ª—é–¥–∞
2. ‚è±Ô∏è –í—Ä–µ–º—è –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏—è –∏ –ø–æ—Ä—Ü–∏–∏
3. üõí –ò–Ω–≥—Ä–µ–¥–∏–µ–Ω—Ç—ã —Å —Ç–æ—á–Ω—ã–º–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞–º–∏
4. üë®‚Äçüç≥ –ü–æ—à–∞–≥–æ–≤–æ–µ –ø—Ä–∏–≥–æ—Ç–æ–≤–ª–µ–Ω–∏–µ (–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫)
5. üìä –ö–ë–ñ–£ –Ω–∞ –ø–æ—Ä—Ü–∏—é (–∫–∞–ª–æ—Ä–∏–∏, –±–µ–ª–∫–∏, –∂–∏—Ä—ã, —É–≥–ª–µ–≤–æ–¥—ã)
6. üí° –°–æ–≤–µ—Ç—ã –ø–æ –ø–æ–¥–∞—á–µ, —Ö—Ä–∞–Ω–µ–Ω–∏—é –∏ –≤–∞—Ä–∏–∞—Ü–∏—è–º

–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ —Ä–µ—Ü–µ–ø—Ç–æ–º, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –≤—Å—Ç—É–ø–ª–µ–Ω–∏–π."""

    payload = {
        "messages": [
            {"role": "system", "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç-–ø–æ–≤–∞—Ä. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": 0.7,
        "top_p": 0.9
    }
    
    model_endpoint = MODELS.get(model, MODELS["llama3"])
    logger.info(f"üß† Generating recipe via {model_endpoint} for: {ingredients[:50]}...")
    
    try:
        result = await _make_request(
            model_endpoint,
            payload,
            timeout=DEFAULT_TIMEOUTS["text"]
        )
        
        if result and "result" in result:
            recipe = result["result"].get("response", "")
            if recipe and len(recipe.strip()) > 50:
                logger.info(f"‚úÖ Recipe generated ({len(recipe)} chars)")
                return recipe.strip()
            logger.warning("‚ö†Ô∏è Empty or too short response from LLM")
            return None
        
        logger.warning("‚ö†Ô∏è No result from LLM API")
        return None
        
    except Exception as e:
        logger.exception(f"üí• generate_recipe error: {e}")
        return None


async def generate_text(
    prompt: str,
    system_prompt: str = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.",
    model: str = "llama3",
    temperature: float = 0.7,
    max_tokens: int = 500
) -> Optional[str]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ LLM.
    
    Args:
        prompt: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        system_prompt: –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç (—Ä–æ–ª—å –º–æ–¥–µ–ª–∏)
        model: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        temperature: –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (0.0-1.0)
        max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
        
    Returns:
        str: –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ None
    """
    payload = {
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": 0.9
    }
    
    model_endpoint = MODELS.get(model, MODELS["llama3"])
    
    try:
        result = await _make_request(
            model_endpoint,
            payload,
            timeout=DEFAULT_TIMEOUTS["text"]
        )
        
        if result and "result" in result:
            return result["result"].get("response", "")
        
        return None
        
    except Exception as e:
        logger.exception(f"üí• generate_text error: {e}")
        return None


# =============================================================================
# üìä –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê (–±—ã—Å—Ç—Ä—ã–µ –∑–∞–¥–∞—á–∏)
# =============================================================================

async def analyze_nutrition_text(text: str) -> Dict[str, float]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ –ö–ë–ñ–£ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –µ–¥—ã.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç TinyLlama –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏.
    
    Args:
        text: –û–ø–∏—Å–∞–Ω–∏–µ –±–ª—é–¥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–∫—É—Ä–∏–Ω–∞—è –≥—Ä—É–¥–∫–∞ 150–≥")
        
    Returns:
        dict: {'calories': float, 'protein': float, 'fat': float, 'carbs': float}
    """
    prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –æ–ø–∏—Å–∞–Ω–∏–µ –µ–¥—ã –∏ –∏–∑–≤–ª–µ–∫–∏ –¥–∞–Ω–Ω—ã–µ –æ –ö–ë–ñ–£.
–¢–µ–∫—Å—Ç: "{text}"

–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û JSON –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
{{"calories": —á–∏—Å–ª–æ, "protein": —á–∏—Å–ª–æ, "fat": —á–∏—Å–ª–æ, "carbs": —á–∏—Å–ª–æ}}
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –≤–µ—Ä–Ω–∏ –Ω—É–ª–∏. –ï–¥–∏–Ω–∏—Ü—ã: –∫–∫–∞–ª –∏ –≥—Ä–∞–º–º—ã.
–ù–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ JSON."""

    payload = {
        "messages": [
            {"role": "system", "content": "–¢—ã –∏–∑–≤–ª–µ–∫–∞–µ—à—å –¥–∞–Ω–Ω—ã–µ –æ –ø–∏—Ç–∞–Ω–∏–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ JSON."},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": 150,
        "temperature": 0.1  # –ú–∏–Ω–∏–º—É–º –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
    }
    
    default_result = {"calories": 0, "protein": 0, "fat": 0, "carbs": 0}
    
    try:
        result = await _make_request(
            MODELS["tinyllama"],
            payload,
            timeout=15  # –ë—ã—Å—Ç—Ä—ã–π —Ç–∞–π–º–∞—É—Ç
        )
        
        if result and "result" in result:
            import json
            response = result["result"].get("response", "")
            # –ü–æ–ø—ã—Ç–∫–∞ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            start = response.find('{')
            end = response.rfind('}') + 1
            if start >= 0 and end > start:
                json_str = response[start:end]
                return json.loads(json_str)
        
        return default_result
        
    except Exception as e:
        logger.error(f"‚ùå Nutrition analysis error: {e}")
        return default_result


# =============================================================================
# üîß –£–¢–ò–õ–ò–¢–´ –ò –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê
# =============================================================================

async def check_api_health() -> Dict[str, bool]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π Cloudflare AI.
    
    Returns:
        dict: {'model_name': True/False} –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    """
    results = {}
    
    async with aiohttp.ClientSession() as session:
        for name, model in MODELS.items():
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
            url = f"https://api.cloudflare.com/client/v4/accounts/{CLOUDFLARE_ACCOUNT_ID}/ai/models/{model.split('/')[-1]}"
            headers = {"Authorization": f"Bearer {CLOUDFLARE_API_TOKEN}"}
            
            try:
                async with session.get(
                    url,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as resp:
                    results[name] = resp.status in (200, 404)  # 404 = –º–æ–¥–µ–ª—å –µ—Å—Ç—å, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–æ –∏–º–µ–Ω–∏
            except:
                results[name] = False
    
    return results


def get_model_info(model_name: str) -> Optional[Dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏ –ø–æ –∏–º–µ–Ω–∏.
    
    Args:
        model_name: –ö–ª—é—á –∏–∑ MODELS (–Ω–∞–ø—Ä–∏–º–µ—Ä, "llama3")
        
    Returns:
        dict: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏ –∏–ª–∏ None
    """
    model_map = {
        "uform_gen2": {
            "type": "vision",
            "description": "–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (UForm-Gen2)",
            "input": "image array + prompt",
            "output": "description text"
        },
        "llava": {
            "type": "vision",
            "description": "–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (LLaVA-1.5)",
            "input": "image array + prompt",
            "output": "description text"
        },
        "whisper": {
            "type": "audio",
            "description": "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (Whisper)",
            "input": "audio file (multipart)",
            "output": "transcribed text"
        },
        "llama3": {
            "type": "text",
            "description": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (Llama 3 8B)",
            "input": "messages array",
            "output": "response text"
        },
        "tinyllama": {
            "type": "text",
            "description": "–ë—ã—Å—Ç—Ä—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ (TinyLlama 1.1B)",
            "input": "messages array",
            "output": "response text"
        }
    }
    return model_map.get(model_name)


async def test_connection() -> Dict[str, Union[bool, str]]:
    """
    –¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Cloudflare AI API.
    
    Returns:
        dict: {'success': bool, 'message': str, 'models_available': int}
    """
    if not _validate_credentials():
        return {
            "success": False,
            "message": "Cloudflare credentials not configured",
            "models_available": 0
        }
    
    try:
        health = await check_api_health()
        available = sum(1 for v in health.values() if v)
        
        return {
            "success": True,
            "message": f"Connected. {available}/{len(health)} models available",
            "models_available": available,
            "details": health
        }
    except Exception as e:
        return {
            "success": False,
            "message": f"Connection test failed: {str(e)}",
            "models_available": 0
        }


# =============================================================================
# üéØ –¢–û–ß–ö–ê –í–•–û–î–ê –î–õ–Ø –¢–ï–°–¢–û–í
# =============================================================================

if __name__ == "__main__":
    import asyncio
    
    async def main():
        print("üîç Testing Cloudflare AI integration...")
        
        # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        conn = await test_connection()
        print(f"Connection: {conn['message']}")
        
        if not conn['success']:
            return
        
        # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ñ–∞–π–ª–æ–≤)
        print("\nüß™ Testing text generation...")
        recipe = await generate_recipe("–∫—É—Ä–∏—Ü–∞, —Ä–∏—Å, –±—Ä–æ–∫–∫–æ–ª–∏")
        if recipe:
            print(f"‚úÖ Recipe preview: {recipe[:200]}...")
        else:
            print("‚ùå Recipe generation failed")
        
        # –¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞
        print("\nüß™ Testing nutrition analysis...")
        nutrition = await analyze_nutrition_text("–∫—É—Ä–∏–Ω–∞—è –≥—Ä—É–¥–∫–∞ 150–≥")
        print(f"‚úÖ Nutrition: {nutrition}")
    
    asyncio.run(main())
